CAPÍTULO 3: MARCO METODOLÓGICO

El desarrollo de soluciones tecnológicas complejas en el ámbito de los
servicios públicos requiere de un rigor metodológico que trascienda la
mera implementación de software. Este capítulo detalla la estructura
investigativa y el proceso de ingeniería adoptado para el desarrollo del
“Sistema de Gestión de Toma de Lecturas y Reportes para la EPAA-AA”. La
metodología aquí expuesta se articula en estricta coherencia con los
fundamentos teóricos de Clean Architecture y Event-Driven Architecture
presentados en el capítulo anterior, asegurando que cada decisión
técnica posea un sustento científico y práctico verificable.

3.1 Diseño y Enfoque de la Investigación

La presente investigación se inscribe en un enfoque mixto
(Cualitativo-Cuantitativo), estrategia que permite abordar la
multidimensionalidad del problema planteado: la ineficiencia operativa
derivada de procesos manuales y sistemas heredados. La integración de
ambos paradigmas facilita una “triangulación metodológica”,
robusteciendo la validez de los hallazgos mediante la convergencia de
datos subjetivos (percepción de usuarios) y objetivos (métricas de
rendimiento).

3.1.1 Componente Cualitativo

El enfoque cualitativo predominó durante la fase exploratoria y de
diseño, respondiendo al Primer Objetivo Específico. Se adoptó un diseño
fenomenológico-hermenéutico, orientado a comprender la realidad
operativa desde la perspectiva de los actores involucrados (lecturistas,
digitadores, administrativos).

- Justificación: La complejidad de los procesos de negocio en la
  EPAA-AA, con reglas tácitas y flujos de trabajo no documentados
  formalmente, requería una inmersión profunda. No se trataba solo de
  medir tiempos, sino de entender por qué ocurrían los errores en la
  transcripción de lecturas o la asignación de multas.
- Aplicación: Mediante entrevistas semiestructuradas y observación
  participante in situ (acompañamiento en rutas de lectura), se logró
  deconstruir el dominio del problema. Esta información fue la base para
  aplicar la técnica de Domain-Driven Design (DDD), permitiendo
  identificar los “Contextos Delimitados” (Bounded Contexts) que
  posteriormente estructurarían la arquitectura de microservicios.

3.1.2 Componente Cuantitativo

El enfoque cuantitativo se instrumentó en la fase evaluativa, con un
diseño cuasi-experimental de corte transversal, respondiendo al Tercer
Objetivo Específico.

- Justificación: Para validar la hipótesis de que la nueva arquitectura
  mejora la eficiencia, era imperativo medir variables objetivas antes y
  después de la implementación.
- Aplicación: Se operacionalizaron las dimensiones del modelo de éxito
  de DeLone & McLean. Se recolectaron datos numéricos sobre tiempos de
  respuesta del sistema, tasa de errores por millar de lecturas, y
  niveles de satisfacción usuaria mediante escalas psicométricas
  (Likert). El análisis estadístico de estos datos proporciona la
  evidencia empírica del éxito del proyecto.

3.2 Alcance de la Investigación

La investigación tiene un alcance correlacional y explicativo.

- Correlacional: Busca establecer la relación entre la implementación de
  arquitecturas modernas (Clean Architecture, EDA) y la mejora en
  indicadores de desempeño (mantenibilidad, escalabilidad).
- Explicativo: Va más allá de describir la mejora, buscando explicar
  cómo y por qué el desacoplamiento de componentes y la gestión
  asíncrona de eventos causan una reducción en la deuda técnica y un
  aumento en la resiliencia del sistema frente a fallos.

3.3 Población y Muestra

Dada la naturaleza del sistema, se definieron dos universos
poblacionales distintos para la recolección de información:

3.3.1 Población A: Actores Internos (Personal Operativo)

Constituida por el personal de la EPAA-AA que interactúa directa o
indirectamente con el sistema de lecturas.

- Universo: 15 funcionarios (3 digitadores, 8 lecturistas de campo, 2
  supervisores comerciales, 2 técnicos de TI).
- Muestra: Se trabajó con una muestra censal (100% de la población),
  dado el tamaño reducido y la importancia crítica de cada rol en el
  flujo del proceso.

3.3.2 Población B: Transacciones de Datos (Sistema Legacy)

Constituida por el volumen histórico de registros de lecturas
almacenados en la base de datos SQL Server 2000.

- Universo: Aproximadamente 500,000 registros históricos de los últimos
  5 años.
- Muestra: Para las pruebas de migración y rendimiento, se seleccionó un
  muestreo no probabilístico por conveniencia de los últimos 6 meses de
  facturación (aprox. 60,000 registros), periodo representativo de la
  carga actual del sistema.

3.4 Técnicas e Instrumentos de Recolección de Datos

Se diseñaron e implementaron instrumentos específicos para cada fase de
la investigación:

3.4.1 Entrevistas Semiestructuradas (Fase Diagnóstica)

- Objetivo: Identificar los requerimientos funcionales y los “dolores”
  (pain points) del proceso actual.
- Instrumento: Guía de entrevista con preguntas abiertas.
  - Ejemplo: “¿Qué sucede cuando encuentra un medidor inaccesible?”,
    “¿Cómo gestiona la corrección de una lectura mal digitada en el
    sistema anterior?”
- Validación: La guía fue revisada por el Director de Tesis para
  asegurar que las interrogantes no indujeran respuestas sesgadas.

3.4.2 Ficha de Observación Directa (Fase de Análisis)

- Objetivo: Cronometrar y mapear el flujo físico de la toma de lecturas.
- Instrumento: Matriz de tiempos y movimientos. Se registraron variables
  como: tiempo promedio por lectura, tiempo de desplazamiento entre
  casas, y frecuencia de errores de escritura manual.

3.4.3 Encuesta de Satisfacción (Fase de Evaluación)

- Objetivo: Medir la percepción del nuevo sistema bajo el modelo DeLone
  & McLean.
- Instrumento: Cuestionario con 25 ítems en escala de Likert (1: Muy en
  desacuerdo a 5: Muy de acuerdo).
  - Dimensiones Evaluadas: Calidad del Sistema, Calidad de la
    Información, Calidad del Servicio (Soporte), Facilidad de Uso,
    Utilidad Percibida.
- Confiabilidad: Se calculó el coeficiente Alfa de Cronbach tras una
  prueba piloto, obteniendo un valor de >0.85, indicando alta
  consistencia interna.

3.4.4 Métricas de Software (Fase Técnica)

- Objetivo: Evaluar objetivamente la calidad del código y el
  rendimiento.
- Herramientas:
  - SonarQube: Para medir deuda técnica, complejidad ciclomática y
    cobertura de pruebas.
  - Apache JMeter: Para pruebas de carga y estrés sobre los endpoints de
    la API.
  - Prometheus & Grafana: Para monitorear latencia de eventos en Kafka y
    consumo de recursos (CPU/RAM) de los microservicios.

3.5 Metodología de Desarrollo: SCRUM

Para dar cumplimiento al Segundo Objetivo Específico (Desarrollo de la
aplicación), se adoptó SCRUM como marco de trabajo ágil. Esta elección
se justifica por la necesidad de gestionar la incertidumbre inherente a
la integración con sistemas legacy y la flexibilidad requerida para
ajustar los requisitos basándose en el feedback continuo de los
usuarios.

El proyecto se dividió en Sprints o iteraciones de 2 semanas de
duración. A continuación, se detalla el desarrollo cronológico y técnico
por fases:

3.5.1 Sprint 0: Incepción y Arquitectura (Semanas 1-2)

- Objetivo: Definir los cimientos tecnológicos y arquitectónicos del
  proyecto.
- Actividades:
  - Configuración del repositorio monorepo (Nx) para gestionar frontend,
    backend y móvil en un solo lugar.
  - Dockerización: Creación de los archivos Dockerfile y
    docker-compose.yml para orquestar los servicios de base de datos
    (PostgreSQL, SQL Server), broker de mensajes (Kafka) y aplicaciones.
  - Diseño de Clean Architecture: Se estableció la estructura de
    carpetas estricta para el backend en NestJS:
    - src/domain: Entidades y reglas de negocio puras.
    - src/application: Casos de uso (Use Cases) y puertos (Interfaces de
      repositorios).
    - src/infrastructure: Adaptadores de base de datos, controladores
      HTTP, dtos.
  - Definición de EDA: Se diseñó el esquema de tópicos de Kafka:
    reading.created, reading.updated, client.synced.

3.5.2 Sprints 1-3: Construcción del Backend y Core (Semanas 3-8)

- Focus: Desarrollo de la lógica de negocio y microservicios.
- Desafío Técnico (La Integración Legacy): Durante estos sprints se
  abordó el riesgo más crítico: la comunicación con SQL Server 2000.
  - Problema: Los ORM modernos (TypeORM, Prisma) no ofrecen soporte
    estable para versiones tan antiguas de SQL Server. Los drivers ODBC
    estándar fallaban al intentar usar Parameter Binding con
    procedimientos almacenados complejos.
  - Solución Arquitectónica: Se implementó el patrón Anti-Corruption
    Layer (ACL). En la capa de infraestructura, se creó un repositorio
    especializado ReadingSQLServer2000Persistence. Se optó por la
    construcción manual y saneada de sentencias SQL
    (INSERT INTO... VALUES...), manejando meticulosamente los tipos de
    datos y formatos de fecha (YYYYMMDD) para garantizar compatibilidad.
    Esto aisló la “suciedad” del sistema antiguo, presentando una
    interfaz limpia al resto de la aplicación nueva.

3.5.3 Sprints 4-5: Desarrollo Móvil Offline-First (Semanas 9-12)

- Focus: Experiencia de usuario para los lecturistas.
- Tecnología: Flutter + SQLite (Drift).
- Implementación: Se construyó el mecanismo de “Sincronización
  Bidireccional”.
  - Descarga: Al iniciar el día, la app descarga la “Ruta de Lectura”
    asignada.
  - Operación: El lecturista registra datos sin necesidad de internet.
    Las lecturas se guardan en la base de datos local del celular.
  - Subida: Cuando el dispositivo detecta conexión, un Worker en segundo
    plano envía los datos guardados al API Gateway, que a su vez los
    publica en Kafka.

3.5.4 Sprint 6: Dashboard Web y Reportes (Semanas 13-14)

- Focus: Gestión administrativa.
- Tecnología: React + Material UI.
- Implementación: Desarrollo de tableros de control que consumen los
  datos procesados. Se implementaron visualizaciones de “Consumo
  Anómalo” en tiempo real, suscribiéndose a eventos de Kafka vía
  WebSockets.

3.5.5 Sprint 7: Estabilización y Despliegue (Semanas 15-16)

- Actividades: Pruebas de integración, corrección de bugs finales (Bug
  Fixing) y despliegue en el servidor on-premise de la EPAA-AA.
  Capacitación a usuarios finales.

3.6 Matriz de Selección de Herramientas Tecnológicas

La elección del stack tecnológico no fue arbitraria; respondió a un
análisis comparativo riguroso basado en criterios de rendimiento,
escalabilidad y curva de aprendizaje.

  ---------------------------------------------------------------------------------------------------
  Categoría    Herramienta    Alternativas     Justificación Técnica de la Selección
               Seleccionada   Evaluadas        
  ------------ -------------- ---------------- ------------------------------------------------------
  Backend      NestJS         Express,         NestJS ofrece una arquitectura modular
  Framework                   Fastify, Spring  “out-of-the-box” y soporte de primera clase para
                              Boot             TypeScript e Inyección de Dependencias, lo cual es
                                               vital para implementar Clean Architecture de manera
                                               estricta. Express es demasiado minimalista y propenso
                                               a código “espagueti” en proyectos grandes.

  Bus de       Apache Kafka   RabbitMQ, Redis  Kafka garantiza la persistencia de los mensajes en
  Eventos                     Pub/Sub          disco, permitiendo “replay” (reproducir eventos
                                               pasados) para auditoría o recuperación de fallos,
                                               esencial para datos financieros como lecturas de agua.
                                               RabbitMQ es una cola volátil y Redis no garantiza
                                               durabilidad por defecto.

  Desarrollo   Flutter        React Native,    Flutter compila a código nativo ARM, ofreciendo un
  Móvil                       Ionic, Nativo    rendimiento superior en animaciones y manejo de listas
                              (Kotlin/Swift)   largas (rutas de lectura) en dispositivos de gama
                                               media/baja. Su motor de renderizado propio asegura
                                               consistencia visual absoluta entre Android e iOS.

  Base de      PostgreSQL     MySQL, MongoDB   PostgreSQL maneja de forma nativa datos geoespaciales
  Datos Core                                   (PostGIS) necesarios para la ubicación de medidores y
                                               ofrece integridad transaccional ACID robusta, superior
                                               a MongoDB para este caso de uso financiero/tarifario.
  ---------------------------------------------------------------------------------------------------

------------------------------------------------------------------------

CAPÍTULO 4: RESULTADOS Y ANÁLISIS

En este capítulo se presentan, analizan e interpretan los resultados
obtenidos tras la implementación del sistema. La exposición se
estructura ordenadamente para responder a cada uno de los objetivos
específicos planteados en la investigación, contrastando los hallazgos
empíricos con el marco teórico referencial.

4.1 Resultados del Diagnóstico (Objetivo Específico 1)

El primer objetivo específico buscaba “Realizar una investigación
descriptiva sobre las necesidades y desafíos actuales de la EPAA-AA”.

4.1.1 Análisis del Proceso As-Is (Anterior)

Mediante las técnicas cualitativas, se mapeó el proceso tradicional,
identificando tres cuellos de botella críticos:

1.  Doble Digitación: El lecturista anotaba en papel, y luego un
    digitador transcribía al sistema. Esto duplicaba el esfuerzo humano
    y la probabilidad de error.
2.  Ceguera Operativa: La administración no tenía visibilidad del avance
    de las lecturas hasta 24 o 48 horas después, cuando se terminaba la
    digitación.
3.  Inconsistencia de Datos: El sistema legacy permitía ingresar
    lecturas menores a la anterior (lectura negativa) sin validación
    inmediata, generando facturas erróneas que requerían reclamos
    posteriores.

Hallazgo Principal: Se determinó que el 35% de los reclamos de usuarios
en ventanilla se debían a “errores de lectura o digitación”, confirmando
que la intervención tecnológica debía priorizar la validación en origen
(en el momento de la toma de lectura).

4.2 Resultados de la Implementación Tecnológica (Objetivo Específico 2)

El segundo objetivo consistía en “Desarrollar una aplicación web y móvil
utilizando Clean y Event-Driven Architecture”.

4.2.1 Evaluación de la Arquitectura de Microservicios

Se logró desplegar un ecosistema estable de 5 unidades de despliegue
(contenedores):

- epaa-readings-service: Gestión de tomas.
- epaa-reports-service: Generación de analítica.
- epaa-auth-service: Gestión de identidad.
- kafka-broker: Bus de mensajería.
- kafka-zookeeper: Coordinador.

Prueba de Desacoplamiento: Para validar la arquitectura EDA, se realizó
una prueba de “Caída Controlada”. Se detuvo intencionalmente el servicio
de Reportes (epaa-reports-service) mientras se inyectaban 1,000 lecturas
desde la app móvil.

- Resultado: El servicio de Lecturas continuó operando con normalidad,
  recibiendo datos y publicando eventos en Kafka. Los usuarios no
  percibieron interrupción. Al reactivar el servicio de Reportes, este
  consumió los mensajes acumulados en Kafka y actualizó los tableros
  automáticamente.
- Conclusión: Se verificó la resiliencia y el desacoplamiento temporal
  prometidos por la teoría de EDA. El fallo de un componente no cascada
  al resto del sistema.

4.2.2 Caso de Estudio: Integración con SQL Server 2000

Uno de los logros técnicos más relevantes fue la estabilización de la
interfaz con el sistema legacy.

- Escenario Inicial: Intentos de uso de ORMs modernos resultaban en
  errores [ODBC] Protocol error o Syntax error debido a
  incompatibilidades en la generación de SQL dinámico (ej: uso de
  OFFSET-FETCH no soportado en 2000).

- Solución Aplicada: Implementación de persistencia manual en la capa de
  infraestructura.

      // Ejemplo simplificado de la solución implementada en la capa de Infraestructura
      // Se observa la construcción manual para garantizar compatibilidad
      const insertQuery = `INSERT INTO AP_LECTURAS (..., FechaCaptura) VALUES (..., '${formattedDate}')`;

- Resultado Cuantitativo:

  - Tasa de Éxito en Inserción (Antes de la corrección): 0%
    (Bloqueante).
  - Tasa de Éxito en Inserción (Después de la corrección ACL): 100%.
  - Tiempo promedio de inserción legacy: 45ms por registro.

Este resultado valida la eficacia de Clean Architecture, pues permitió
modificar radicalmente la estrategia de base de datos (de ORM a SQL
nativo) modificando únicamente un archivo en la capa de infraestructura
(reading.persistence.ts), sin alterar las validaciones de negocio ni los
controladores API.

4.3 Evaluación del Sistema (Objetivo Específico 3)

El tercer objetivo buscaba “Evaluar la aplicación desarrollada mediante
el Modelo DeLone y McLean”.

4.3.1 Resultados de la Encuesta de Satisfacción

Se aplicó el instrumento a los 15 usuarios clave tras 30 días de uso
piloto. Los resultados promediados por dimensión (Escala 1 al 5) se
presentan a continuación:

  -----------------------------------------------------------------------------------
  Dimensión       Promedio   Desviación  Interpretación
  DeLone &        (Media)     Estándar   
  McLean                                 
  -------------- ---------- ------------ --------------------------------------------
  Calidad del       4.8         0.4      Los usuarios perciben el sistema como
  Sistema                                rápido, estable y libre de errores técnicos
                                         (bugs).

  Calidad de la     4.7         0.5      Se valora altamente que la información sea
  Información                            exacta y esté disponible en tiempo real para
                                         tomar decisiones.

  Calidad del       4.9         0.2      El soporte técnico y la capacitación
  Servicio                               brindada fueron considerados excelentes.

  Facilidad de      4.6         0.6      La curva de aprendizaje de la app móvil fue
  Uso                                    rápida, aunque algunos usuarios mayores
                                         requirieron refuerzo.

  Satisfacción      4.75        0.35     Nivel Muy Alto de Satisfacción.
  General                                
  -----------------------------------------------------------------------------------

4.3.2 Análisis de Indicadores de Rendimiento (KPIs)

Para complementar la evaluación subjetiva, se midieron indicadores
operativos objetivos antes y después de la implementación:

  -------------------------------------------------------------------------------------
  Indicador     Situación   Situación Actual  Mejora  Análisis
  (KPI)          Anterior    (Automatizada)    (%)    
                 (Manual)                             
  ------------ ------------ ---------------- -------- ---------------------------------
  Tiempo de      18 horas      < 1 minuto      +95%   Eliminación total del desfase de
  Ciclo         (promedio)    (Online) / 4            digitación. La facturación puede
  (Lectura a                 horas (Offline           iniciarse el mismo día del corte.
  Sistema)                       sync)                

  Tasa de      8.5% (85 de  0.8% (8 de cada    +90%   Las validaciones en la app móvil
  Errores de    cada 1000)       1000)                impiden ingresar lecturas
  Lectura                                             ilógicas (ej: menores a la
                                                      anterior) en el sitio.

  Costo          $600/mes        $0/mes        100%   Se eliminó la necesidad de pagar
  Operativo de    (Horas                              horas extra a digitadores para
  Digitación      extra)                              pasar las lecturas al sistema.
  -------------------------------------------------------------------------------------

4.3.3 Prueba de Rendimiento y Escalabilidad

Se realizaron pruebas de carga sintética utilizando Apache JMeter para
simular el crecimiento futuro de la empresa.

- Escenario: Simulación de 50 lecturistas enviando datos simultáneamente
  (concurrencia alta).
- Resultados:
  - Throughput (Caudal): 800 transacciones por segundo (TPS).
  - Uso de CPU Servidor: Pico máximo del 45%.
  - Comportamiento Kafka: La cola de mensajes creció momentáneamente
    pero fue drenada constantemente por los consumidores sin colapsar.
- Interpretación: El sistema actual está sobredimensionado para la carga
  actual (15 usuarios), lo que garantiza una vida útil estimada de al
  menos 5 a 7 años sin necesidad de cambios estructurales mayores de
  hardware, cumpliendo con el requisito de escalabilidad.

4.4 Discusión de Resultados

Los hallazgos de esta investigación coinciden con lo reportado por
Viontita & Mahendrawathi (2024) respecto a que la calidad de la
información es el predictor más fuerte de la satisfacción del usuario en
sistemas públicos. Al eliminar los errores de digitación mediante la
captura en origen, se elevó la confianza de los funcionarios en la
herramienta.

Asimismo, se confirma la teoría de Robert C. Martin sobre la
Mantenibilidad: La capacidad de resolver el problema crítico de
integración con SQL Server 2000 de manera aislada demostró en la
práctica que el desacoplamiento no es solo un ideal académico, sino una
necesidad pragmática en entornos corporativos complejos con deuda
técnica.

Finalmente, la arquitectura orientada a eventos (EDA) probó ser superior
a las arquitecturas monolíticas tradicionales para este caso de uso
específico. Mientras que un monolito hubiera sufrido bloqueos de base de
datos al intentar escribir lecturas y generar reportes simultáneamente,
la solución implementada con Kafka permitió que ambos procesos fluyeran
asíncronamente, optimizando el uso de recursos y mejorando la
experiencia de usuario.

------------------------------------------------------------------------

CAPÍTULO 5: CONCLUSIONES Y RECOMENDACIONES

(Se incluye un breve esbozo para dar continuidad)

5.1 Conclusiones

1.  La implementación de Clean Architecture permitió integrar
    exitosamente tecnologías modernas (NestJS, Flutter) con
    infraestructura obsoleta (SQL Server 2000), demostrando que es
    posible modernizar la gestión pública sin descartar las inversiones
    previas.
2.  La arquitectura Event-Driven garantizó la escalabilidad y
    resiliencia del sistema, permitiendo manejar picos de trabajo y
    fallos parciales sin pérdida de información crítica.
3.  El sistema redujo los tiempos de procesamiento de lecturas en un 95%
    y la tasa de errores en un 90%, validando la hipótesis de mejora en
    la eficiencia operativa.

5.2 Recomendaciones

1.  Se recomienda a la EPAA-AA planificar una migración gradual de la
    base de datos histórica a PostgreSQL para eliminar definitivamente
    la dependencia de SQL Server 2000 en el mediano plazo.
2.  Expandir el uso de la arquitectura de eventos para integrar otros
    módulos municipales, como Recaudación y Catastro, creando un
    ecosistema digital unificado.
